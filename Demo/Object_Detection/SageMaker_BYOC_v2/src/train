#!/usr/bin/env python

# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"). You
# may not use this file except in compliance with the License. A copy of
# the License is located at
#
#     http://aws.amazon.com/apache2.0/
#
# or in the "license" file accompanying this file. This file is
# distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
# ANY KIND, either express or implied. See the License for the specific
# language governing permissions and limitations under the License.

# Applied from https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/keras_bring_your_own
from __future__ import absolute_import
from __future__ import print_function

import keras
from keras.preprocessing.image import *
from keras.models import Sequential, Model
from keras.layers import Conv2D, Flatten, Lambda, ELU
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import Adam
from keras.callbacks import Callback, ModelCheckpoint
from keras.layers.normalization import BatchNormalization
from keras.regularizers import l2
from keras.utils import multi_gpu_model
from sklearn.model_selection import train_test_split
import os, shutil, random, json, glob, cv2, sys, traceback
import numpy as np
import pandas as pd
import matplotlib.image as mpimg

from environment import create_trainer_environment

# Global parameters
IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3
IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)
MODEL_NAME = 'model.h5'

# Configure the trainer environemnt for SageMaker training
env = create_trainer_environment()
print('creating SageMaker trainer environment:\n%s' % str(env))

# Get hyperparameters
batch_size = env.hyperparameters.get('batch_size', default=16, object_type=int)
learning_rate = env.hyperparameters.get('learning_rate', default=.001, object_type=float)
EPOCHS = env.hyperparameters.get('epochs', default=10, object_type=int)
gpu_count = env.hyperparameters.get('gpu_count', default=0, object_type=int)

# Helper functions for Image Augmentation
def load_image(data_dir, image_file):
    """
    Load RGB images from a file
    """
    return mpimg.imread(os.path.join(data_dir, image_file.strip()))

def crop(image):
    """
    Crop the image (removing the sky at the top and the car front at the bottom)
    """
    return image[60:-25, :, :] # remove the sky and the car front

def resize(image):
    """
    Resize the image to the input shape used by the network model
    """
    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)

def rgb2yuv(image):
    """
    Convert the image from RGB to YUV (This is what the NVIDIA model does)
    """
    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)

def preprocess(image):
    """
    Combine all preprocess functions into one
    """
    image = crop(image)
    image = resize(image)
    image = rgb2yuv(image)
    return image

def choose_image(data_dir, center, left, right, steering_angle):
    """
    Randomly choose an image from the center, left or right, and adjust
    the steering angle.
    """
    choice = np.random.choice(3)
    if choice == 0:
        return load_image(data_dir, left), steering_angle + 0.2
    elif choice == 1:
        return load_image(data_dir, right), steering_angle - 0.2
    return load_image(data_dir, center), steering_angle

def random_flip(image, steering_angle):
    """
    Randomly flipt the image left <-> right, and adjust the steering angle.
    """
    if np.random.rand() < 0.5:
        image = cv2.flip(image, 1)
        steering_angle = -steering_angle
    return image, steering_angle

def random_translate(image, steering_angle, range_x, range_y):
    """
    Randomly shift the image virtially and horizontally (translation).
    """
    trans_x = range_x * (np.random.rand() - 0.5)
    trans_y = range_y * (np.random.rand() - 0.5)
    steering_angle += trans_x * 0.002
    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])
    height, width = image.shape[:2]
    image = cv2.warpAffine(image, trans_m, (width, height))
    return image, steering_angle

def distort(image):
    """
    Method for adding random distortion to dataset images, including random brightness adjust, and a random
    vertical shift of the horizon position
    """
    new_img = image.astype(float)
    # random brightness - the mask bit keeps values from going beyond (0,255)
    value = np.random.randint(-28, 28)
    if value > 0:
        mask = (new_img[:,:,0] + value) > 255 
    if value <= 0:
        mask = (new_img[:,:,0] + value) < 0
    new_img[:,:,0] += np.where(mask, 0, value)
    # random shadow - full height, random left/right side, random darkening
    h,w = new_img.shape[0:2]
    mid = np.random.randint(0,w)
    factor = np.random.uniform(0.6,0.8)
    if np.random.rand() > .5:
        new_img[:,0:mid,0] *= factor
    else:
        new_img[:,mid:w,0] *= factor
    # randomly shift horizon
    h,w,_ = new_img.shape
    horizon = 2*h/5
    v_shift = np.random.randint(-h/8,h/8)
    pts1 = np.float32([[0,horizon],[w,horizon],[0,h],[w,h]])
    pts2 = np.float32([[0,horizon+v_shift],[w,horizon+v_shift],[0,h],[w,h]])
    M = cv2.getPerspectiveTransform(pts1,pts2)
    new_img = cv2.warpPerspective(new_img,M,(w,h), borderMode=cv2.BORDER_REPLICATE)
    return new_img.astype(np.uint8)

def random_brightness(image):
    """
    Randomly adjust brightness of the image.
    """
    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)
    hsv[:,:,2] =  hsv[:,:,2] * ratio
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

def augment(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):
    """
    Generate an augumented image and adjust steering angle.
    (The steering angle is associated with the center image)
    """
    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)
    image, steering_angle = random_flip(image, steering_angle)
    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)
    image = distort(image)
    image = random_brightness(image)
    return image, steering_angle

def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):
    """
    Generate training image give image paths and associated steering angles
    """
    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])
    steers = np.empty(batch_size)
    while True:
        i = 0
        for index in np.random.permutation(image_paths.shape[0]):
            center, left, right = image_paths[index]
            steering_angle = steering_angles[index]
            # argumentation
            if is_training and np.random.rand() < 1.:
                image, steering_angle = augment(data_dir, center, left, right, steering_angle)
            else:
                image = load_image(data_dir, center) 
            # add the image and steering angle to the batch
            images[i] = preprocess(image)
            steers[i] = steering_angle
            i += 1
            if i == batch_size:
                break
        yield images, steers

# Helper functions for model training
def load_data(data_dir, test_size):
    """
    Load training data and split it into training and validation set
    """
    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'))

    X = data_df[['center', 'left', 'right']].values
    y = data_df['steering'].values

    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=0)

    return X_train, X_valid, y_train, y_valid

def build_model(input_shape):
    """
    Comma.ai model
    """
    model = Sequential()
    model.add(
        Lambda(
            lambda x: x/127.55 -1,
            input_shape=input_shape
        )
    )
    model.add(Conv2D(16, (8, 8), strides=(4, 4), padding="same"))
    model.add(ELU())
    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding="same"))
    model.add(ELU())
    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding="same"))
    model.add(Flatten())
    model.add(Dropout(.2))
    model.add(ELU())
    model.add(Dense(512))
    model.add(Dropout(.5))
    model.add(ELU())
    model.add(Dense(1))
    model.summary()
    return model

def save(model, model_dir):
    print("Saving the trained model ...")
    files = list(glob.glob(os.path.join(model_dir, '*.h5')))
    
    # Find the best model weights
    best = max(files)
    
    # Rename the best weights
    #os.rename(best, MODEL_NAME)
    shutil.copy(best, os.path.join(model_dir, MODEL_NAME))
    
    # Move to model_dir
    #shutil.copy('./model.h5', model_dir+'/')
    
#    # Save model graph to `.json`
#    model_json = model.to_json()
#    with open(model_dir+'/model.json', 'w') as outfile:
#        json.dump(model_json, outfile)

# Training function
def train():
    print("Starting model training ...")
    # Local variables
    data_dir = os.path.join(env.channel_dirs['train'], 'data')
    test_size = 0.1

    # Load the data
    X_train, X_valid, y_train, y_valid = load_data(data_dir, test_size)
        
    # Load the model and additional parameters
    print("\ncomma.ai Model Summary\n")
    model = build_model(IMAGE_SHAPE)
        
    # Save model Checpoint
    checkpoint = ModelCheckpoint(
        os.path.join(env.model_dir, 'model-{epoch:03d}.h5'),
        verbose=0,
        save_best_only=1,
        mode='auto'
    )

    # Compile model
    if gpu_count > 1:
        model = multi_gpu_model(model, gpus=gpu_count)
    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))
        
    # Fit the model
    model.fit_generator(
        batch_generator(
            data_dir,
            X_train,
            y_train,
            batch_size,
            True
        ),
        steps_per_epoch=len(X_train)//batch_size,
        epochs=EPOCHS,
#        max_queue_size=1,
        validation_data=batch_generator(
            data_dir,
            X_valid,
            y_valid,
            batch_size,
            False
        ),
        validation_steps=len(X_valid)//batch_size,
        callbacks=[checkpoint],
        verbose=1
    )

    # Save the model
    save(model, env.model_dir)

if __name__ == '__main__':
    train()
    sys.exit(0)