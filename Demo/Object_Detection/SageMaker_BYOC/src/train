#!/usr/bin/env python

# Applied from https://github.com/pierluigiferrari/ssd_keras
from __future__ import absolute_import
from __future__ import print_function

import keras
from keras.optimizers import Adam, SGD
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger
from keras import backend as K
from keras.models import load_model
from math import ceil
import numpy as np

from models.keras_ssd300 import ssd_300
from keras_loss_function.keras_ssd_loss import SSDLoss
from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes
from keras_layers.keras_layer_DecodeDetections import DecodeDetections
from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast
from keras_layers.keras_layer_L2Normalization import L2Normalization

from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder
from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast

from data_generator.object_detection_2d_data_generator import DataGenerator
from data_generator.object_detection_2d_geometric_ops import Resize
from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels
from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation
from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms

from environment import create_trainer_environment

# Global parameters
IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 300, 300, 3
IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)
# The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.
MEAN_COLOR = [123, 117, 104]
# The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.
SWAP_CHANNELS = [2, 1, 0]
# The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets
SCALES = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]
# The anchor box aspect ratios used in the original SSD300; the order matters
ASPECT_RATIOS = [[1.0, 2.0, 0.5],
                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                 [1.0, 2.0, 0.5],
                 [1.0, 2.0, 0.5]]
# The space between two adjacent anchor box center points for each predictor layer.
STEPS = [8, 16, 32, 64, 100, 300]
# The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.
OFFSETS= [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
# Whether or not to clip the anchor boxes to lie entirely within the image boundaries
CLIP_BOXES = False
# The variances by which the encoded target coordinates are divided as in the original implementation
VARIANCES = [0.1, 0.1, 0.2, 0.2]
NORMALIZE_COORDS = True
# The XML parser needs to now what object class names to look for and in which order to map them to integers.
CLASSES = ['background',
           'aeroplane', 'bicycle', 'bird', 'boat',
           'bottle', 'bus', 'car', 'cat',
           'chair', 'cow', 'diningtable', 'dog',
           'horse', 'motorbike', 'person', 'pottedplant',
           'sheep', 'sofa', 'train', 'tvmonitor']
N_CLASSES = len(CLASSES)-1
MODEL_NAME = 'model.h5'

# Configure the trainer environemnt for SageMaker training
env = create_trainer_environment()
print('creating SageMaker trainer environment:\n%s' % str(env))

# Get hyperparameters
batch_size = env.hyperparameters.get('batch_size', default=32, object_type=int)
#batch_size = 32
lr = env.hyperparameters.get('learning_rate', default=.001, object_type=float)
alpha = env.hyperparameters.get('alpha', default=1.0, object_type=float)
beta_1 = env.hyperparameters.get('beta_1', default=0.9, object_type=float)
beta_2 = env.hyperparameters.get('beta_2', default=0.999, object_type=float)
epsilon = env.hyperparameters,get('eposilon', default==1e-08, object_type=float)
decay = env.hyperparameters.get('decay', default=0.0, object_type=float)
EPOCHS = env.hyperparameters.get('epochs', default=10, object_type=int)
gpu_count = env.hyperparameters.get('gpu_count', default=0, object_type=int)

# Helper functions for model training
def lr_schedule(epoch):
    """
    Define a learning rate schedule.
    """
    if epoch < 80:
        return 0.001
    elif epoch < 100:
        return 0.0001
    else:
        return 0.00001

def load_data(data_dir):
    """
    Load training data and split it into training and validation set
    """
    train_dataset = DataGenerator(
        load_images_into_memory=True,
        hdf5_dataset_path=os.path.join(data_dir, 'train.h5')
    )
    val_dataset = DataGenerator(
        load_images_into_memory=True,
        hdf5_dataset_path=os.path.join(data_dir, 'test.h5')
    )

    # For the training generator:
    ssd_data_augmentation = SSDDataAugmentation(img_height=IMAGE_HEIGHT,
                                                img_width=IMAGE_WIDTH,
                                                background=MEAN_COLOR)

    # For the validation generator:
    convert_to_3_channels = ConvertTo3Channels()
    resize = Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH)

    # The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.
    predictor_sizes = [model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],
                    model.get_layer('fc7_mbox_conf').output_shape[1:3],
                    model.get_layer('conv6_2_mbox_conf').output_shape[1:3],
                    model.get_layer('conv7_2_mbox_conf').output_shape[1:3],
                    model.get_layer('conv8_2_mbox_conf').output_shape[1:3],
                    model.get_layer('conv9_2_mbox_conf').output_shape[1:3]]

    ssd_input_encoder = SSDInputEncoder(img_height=IMAGE_HEIGHT,
                                        img_width=IMAGE_WIDTH,
                                        n_classes=N_CLASSES,
                                        predictor_sizes=predictor_sizes,
                                        scales=SCALES,
                                        aspect_ratios_per_layer=ASPECT_RATIOS,
                                        two_boxes_for_ar1=True,
                                        steps=STEPS,
                                        offsets=OFFSETS,
                                        clip_boxes=CLIP_BOXES,
                                        variances=VARIANCES,
                                        matching_type='multi',
                                        pos_iou_threshold=0.5,
                                        neg_iou_limit=0.5,
                                        normalize_coords=NORMALIZE_COORDS
                                    )

    # Create the generator handles that will be passed to Keras' `fit_generator()` function.
    train_generator = train_dataset.generate(batch_size=batch_size,
                                            shuffle=True,
                                            transformations=[ssd_data_augmentation],
                                            label_encoder=ssd_input_encoder,
                                            returns={'processed_images',
                                                    'encoded_labels'},
                                            keep_images_without_gt=False)

    val_generator = val_dataset.generate(batch_size=batch_size,
                                        shuffle=False,
                                        transformations=[convert_to_3_channels,
                                                        resize],
                                        label_encoder=ssd_input_encoder,
                                        returns={'processed_images',
                                                'encoded_labels'},
                                        keep_images_without_gt=False)

    return train_generator, val_generator

def save(model, model_dir):
    print("Saving the trained model ...")
    files = list(glob.glob(os.path.join(model_dir, '*.h5')))
    
    # Find the best model weights
    best = max(files)
    
    # Rename the best weights
    #os.rename(best, MODEL_NAME)
    shutil.copy(best, os.path.join(model_dir, MODEL_NAME))
    
    # Move to model_dir
    #shutil.copy('./model.h5', model_dir+'/')
    
#    # Save model graph to `.json`
#    model_json = model.to_json()
#    with open(model_dir+'/model.json', 'w') as outfile:
#        json.dump(model_json, outfile)

# Training function
def train():
    print("Starting model training ...")
    # Local variables
    data_dir = os.path.join(env.channel_dirs['train'], 'data')

    # Load the data
    traing_generator, val_generator = load_data(data_dir)
        
    # Load the model and additional parameters
    model = ssd_300(image_size=IMAGE_SHAPE,
                    n_classes=N_CLASSES,
                    mode='training',
                    l2_regularization=0.0005,
                    scales=SCALES,
                    aspect_ratios_per_layer=ASPECT_RATIOS,
                    two_boxes_for_ar1=True,
                    steps=STEPS,
                    offsets=OFFSETS,
                    clip_boxes=CLIP_BOXES,
                    variances=VARIANCES,
                    normalize_coords=NORMALIZE_COORDS,
                    subtract_mean=MEAN_COLOR,
                    swap_channels=SWAP_CHANNELS
                )

    weights_path = './VGG_ILSVRC_16_layers_fc_reduced.h5'
    model.load_weights(weights_path, by_name=True)
    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)
        
    # Save model Checkpoint
    model_checkpoint = ModelCheckpoint(
        filepath=os.path.join(env.model_dir, 'model-{epoch:03d}.h5'),
        monitor='val_loss',
        verbose=1,
        save_best_only=True,
        save_weights_only=False,
        mode='auto',
        period=1
    )
    
    csv_logger = CSVLogger(
        filename=os.path.join(env.model_dir, 'training_log.csv'),
        separator=',',
        append=True
    )

    learning_rate_scheduler = LearningRateScheduler(
        schedule=lr_schedule,
        verbose=1
    )
    terminate_on_nan = TerminateOnNaN()

    callbacks = [model_checkpoint,
             csv_logger,
             learning_rate_scheduler,
             terminate_on_nan]

    # Compile model
    if gpu_count > 1:
        model = multi_gpu_model(model, gpus=gpu_count)
    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)
        
    # Fit the model
    initial_epoch   = 0
    final_epoch     = 120
    steps_per_epoch = 1000
    
    model.fit_generator(
        generator=train_generator,
        steps_per_epoch=steps_per_epoch,
        epochs=final_epoch,
        callbacks=callbacks,
        validation_data=val_generator,
        validation_steps=ceil(val_dataset_size/batch_size),
        initial_epoch=initial_epoch
    )

    # Save the model
    save(model, env.model_dir)

if __name__ == '__main__':
    train()
    sys.exit(0)