{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -O /tmp/VOCtrainval_11-May-2012.tar\n",
    "!tar xf /tmp/VOCtrainval_11-May-2012.tar -C /tmp/\n",
    "!rm -rf /tmp/VOCtrainval_11-May-2012.tar\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar -O /tmp/VOCtrainval_06-Nov-2007.tar\n",
    "!tar xf /tmp/VOCtrainval_06-Nov-2007.tar -C /tmp/\n",
    "!rm -rf /tmp/VOCtrainval_06-Nov-2007.tar\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar -O /tmp/VOCtest_06-Nov-2007.tar\n",
    "!tar xf /tmp/VOCtest_06-Nov-2007.tar -C /tmp/\n",
    "!rm -rf /tmp/VOCtest_06-Nov-2007.tar\n",
    "```\n",
    "\n",
    "```\n",
    "--2018-10-19 21:39:14--  http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
    "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 1999639040 (1.9G) [application/x-tar]\n",
    "Saving to: ‘/tmp/VOCtrainval_11-May-2012.tar’\n",
    "\n",
    "/tmp/VOCtrainval_11 100%[===================>]   1.86G  7.45MB/s    in 4m 6s   \n",
    "\n",
    "2018-10-19 21:43:20 (7.76 MB/s) - ‘/tmp/VOCtrainval_11-May-2012.tar’ saved [1999639040/1999639040]\n",
    "\n",
    "--2018-10-19 21:43:23--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
    "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 460032000 (439M) [application/x-tar]\n",
    "Saving to: ‘/tmp/VOCtrainval_06-Nov-2007.tar’\n",
    "\n",
    "/tmp/VOCtrainval_06 100%[===================>] 438.72M  8.17MB/s    in 60s     \n",
    "\n",
    "2018-10-19 21:44:24 (7.27 MB/s) - ‘/tmp/VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
    "\n",
    "--2018-10-19 21:44:25--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
    "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 451020800 (430M) [application/x-tar]\n",
    "Saving to: ‘/tmp/VOCtest_06-Nov-2007.tar’\n",
    "\n",
    "/tmp/VOCtest_06-Nov 100%[===================>] 430.13M  8.06MB/s    in 56s     \n",
    "\n",
    "2018-10-19 21:45:22 (7.63 MB/s) - ‘/tmp/VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default classes for VOCdevkit\n",
    "classes = ['background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat',\n",
    "           'chair', 'cow', 'diningtable', 'dog',\n",
    "           'horse', 'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "# Initialize the Batch generator for datasets\n",
    "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "# The directories that contain the images.\n",
    "VOC_2007_images_dir      = '/tmp/VOCdevkit/VOC2007/JPEGImages/'\n",
    "VOC_2012_images_dir      = '/tmp/VOCdevkit/VOC2012/JPEGImages/'\n",
    "\n",
    "# The directories that contain the annotations.\n",
    "VOC_2007_annotations_dir      = '/tmp/VOCdevkit/VOC2007/Annotations/'\n",
    "VOC_2012_annotations_dir      = '/tmp/VOCdevkit/VOC2012/Annotations/'\n",
    "\n",
    "# The paths to the image sets.\n",
    "VOC_2007_train_image_set_filename    = '/tmp/VOCdevkit/VOC2007/ImageSets/Main/train.txt'\n",
    "VOC_2012_train_image_set_filename    = '/tmp/VOCdevkit/VOC2012/ImageSets/Main/train.txt'\n",
    "VOC_2007_val_image_set_filename      = '/tmp/VOCdevkit/VOC2007/ImageSets/Main/val.txt'\n",
    "VOC_2012_val_image_set_filename      = '/tmp/VOCdevkit/VOC2012/ImageSets/Main/val.txt'\n",
    "VOC_2007_trainval_image_set_filename = '/tmp/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'\n",
    "VOC_2012_trainval_image_set_filename = '/tmp/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt'\n",
    "VOC_2007_test_image_set_filename     = '/tmp/VOCdevkit/VOC2007/ImageSets/Main/test.txt'\n",
    "\n",
    "# Create Training Dataset\n",
    "train_dataset.parse_xml(images_dirs=[VOC_2007_images_dir,\n",
    "                                     VOC_2012_images_dir],\n",
    "                        image_set_filenames=[VOC_2007_trainval_image_set_filename,\n",
    "                                             VOC_2012_trainval_image_set_filename],\n",
    "                        annotations_dirs=[VOC_2007_annotations_dir,\n",
    "                                          VOC_2012_annotations_dir],\n",
    "                        classes=classes,\n",
    "                        include_classes='all',\n",
    "                        exclude_truncated=False,\n",
    "                        exclude_difficult=False,\n",
    "                        ret=False)\n",
    "\n",
    "# Create Testing Dataset\n",
    "val_dataset.parse_xml(images_dirs=[VOC_2007_images_dir],\n",
    "                      image_set_filenames=[VOC_2007_test_image_set_filename],\n",
    "                      annotations_dirs=[VOC_2007_annotations_dir],\n",
    "                      classes=classes,\n",
    "                      include_classes='all',\n",
    "                      exclude_truncated=False,\n",
    "                      exclude_difficult=True,\n",
    "                      ret=False)\n",
    "\n",
    "# Convert the dataset into an HDF5 dataset fpor S3 upload\n",
    "train_dataset.create_hdf5_dataset(file_path='/tmp/train.h5',\n",
    "                                  resize=False,\n",
    "                                  variable_image_size=True,\n",
    "                                  verbose=True)\n",
    "\n",
    "val_dataset.create_hdf5_dataset(file_path='/tmp/test.h5',\n",
    "                                resize=False,\n",
    "                                variable_image_size=True,\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'data'\n",
    "channels = {'train': 's3://{}'.format(bucket)}\n",
    "#sagemaker_session.upload_data(path='/tmp/train.h5', bucket=bucket, key_prefix=prefix)\n",
    "#sagemaker_session.upload_data(path='/tmp/test.h5', bucket=bucket, key_prefix=prefix)\n",
    "hyperparameters = dict(learning_rate=.001, epochs=30)\n",
    "output_location = 's3://{}/output'.format(bucket)\n",
    "image_name = '500842391574.dkr.ecr.us-west-2.amazonaws.com/keras:keras-gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYOC_estimator = Estimator(\n",
    "    image_name,\n",
    "    role=role,\n",
    "    output_path=output_location,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: keras-2018-10-19-23-15-25-366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-19 23:15:25 Starting - Starting the training job...\n",
      "2018-10-19 23:15:26 Starting - Launching requested ML instances......"
     ]
    }
   ],
   "source": [
    "BYOC_estimator.fit(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
