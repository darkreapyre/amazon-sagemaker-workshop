{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===== import SSD for keras 2 =====\n",
    "from ssd_v2 import SSD300v2\n",
    "from ssd_utils import BBoxUtility\n",
    "# ===== import SSD for keras 2 =====\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95#0.45\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_classes = ['Aeroplane', 'Bicycle', 'Bird', 'Boat', 'Bottle',\n",
    "               'Bus', 'Car', 'Cat', 'Chair', 'Cow', 'Diningtable',\n",
    "               'Dog', 'Horse','Motorbike', 'Person', 'Pottedplant',\n",
    "               'Sheep', 'Sofa', 'Train', 'Tvmonitor']\n",
    "NUM_CLASSES = len(voc_classes) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(300, 300, 3)\n",
    "model = SSD300v2(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights('weights_SSD300.hdf5', by_name=True)\n",
    "bbox_util = BBoxUtility(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(xmin, ymin, xmax, ymax):\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def center_is_near(prev_bbox, bbox):\n",
    "    IS_NEAR_THRESHOLD = 30\n",
    "    \n",
    "    prev_center_x = (prev_bbox[0] + prev_bbox[2])/2.\n",
    "    prev_center_y = (prev_bbox[1] + prev_bbox[3])/2.\n",
    "    center_x = (bbox[0] + bbox[2])/2.\n",
    "    center_y = (bbox[1] + bbox[3])/2.\n",
    "    \n",
    "    dist = np.sqrt((prev_center_x - center_x)**2 + (prev_center_y - center_y)**2)\n",
    "    \n",
    "    if dist <= IS_NEAR_THRESHOLD:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def draw_boxes(img, preds, results):\n",
    "    global first_frame_has_car, prev_bboxes, prev_bboxes_len, bbox_disappear_frame_count\n",
    "    \n",
    "    # Parse the outputs.\n",
    "    det_label = results[0][:, 0]\n",
    "    det_conf = results[0][:, 1]\n",
    "    det_xmin = results[0][:, 2]\n",
    "    det_ymin = results[0][:, 3]\n",
    "    det_xmax = results[0][:, 4]\n",
    "    det_ymax = results[0][:, 5]\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "    \n",
    "    bboxes_len = 0\n",
    "    bboxes = []   \n",
    "    for i in range(top_conf.shape[0]):\n",
    "        \n",
    "        label = int(top_label_indices[i])        \n",
    "        label_name = voc_classes[label - 1]\n",
    "        \n",
    "        if label_name == 'Car':\n",
    "            bboxes_len += 1\n",
    "            \n",
    "            xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "            ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "            xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "            ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "            \n",
    "            if first_frame_has_car or len(prev_bboxes) == 0:\n",
    "                prev_bboxes.append(get_bbox(xmin, ymin, xmax, ymax))\n",
    "                first_frame_has_car = False\n",
    "                prev_bboxes_len = 0\n",
    "            else:\n",
    "                has_near_in_prev_bboxes = False\n",
    "                for i_prev_bbox in range(len(prev_bboxes)):\n",
    "                    if center_is_near(prev_bboxes[i_prev_bbox], [xmin, ymin, xmax, ymax]):\n",
    "                        ratiox = 0.5\n",
    "                        ratioy = 0.65\n",
    "                        xmin = int((1-ratiox)*xmin + ratiox*prev_bboxes[i_prev_bbox][0])\n",
    "                        ymin = int((1-ratioy)*ymin + ratioy*prev_bboxes[i_prev_bbox][1])\n",
    "                        xmax = int((1-ratiox)*xmax + ratiox*prev_bboxes[i_prev_bbox][2])\n",
    "                        ymax = int((1-ratioy)*ymax + ratioy*prev_bboxes[i_prev_bbox][3])\n",
    "                        prev_bboxes[i_prev_bbox][0] = xmin \n",
    "                        prev_bboxes[i_prev_bbox][1] = ymin\n",
    "                        prev_bboxes[i_prev_bbox][2] = xmax\n",
    "                        prev_bboxes[i_prev_bbox][3] = ymax\n",
    "                        has_near_in_prev_bboxes = True\n",
    "                        \n",
    "                if not has_near_in_prev_bboxes:\n",
    "                    prev_bboxes.append(get_bbox(xmin, ymin, xmax, ymax))\n",
    "                    \n",
    "            bboxes.append(get_bbox(xmin, ymin, xmax, ymax))  \n",
    "           \n",
    "    if prev_bboxes_len > bboxes_len and bbox_disappear_frame_count < 5:\n",
    "        for i_prev_bbox in range(len(prev_bboxes)):\n",
    "            for i_bbox in range(len(bboxes)):\n",
    "                if not center_is_near(prev_bboxes[i_prev_bbox], bboxes[i_bbox]):\n",
    "                    cv2.rectangle(img, \n",
    "                                  (prev_bboxes[i_prev_bbox][0],prev_bboxes[i_prev_bbox][1]), \n",
    "                                  (prev_bboxes[i_prev_bbox][2],prev_bboxes[i_prev_bbox][3]), (0,255,0), 5)\n",
    "            if len(bboxes) == 0:\n",
    "                cv2.rectangle(img, \n",
    "                              (prev_bboxes[i_prev_bbox][0],prev_bboxes[i_prev_bbox][1]), \n",
    "                              (prev_bboxes[i_prev_bbox][2],prev_bboxes[i_prev_bbox][3]), (0,255,0), 5)\n",
    "        bbox_disappear_frame_count += 1\n",
    "    else:\n",
    "        bbox_disappear_frame_count = 0\n",
    "        prev_bboxes_len = len(bboxes)\n",
    "        prev_bboxes = bboxes\n",
    "    for i_bbox in range(len(bboxes)):\n",
    "        cv2.rectangle(img, (bboxes[i_bbox][0],bboxes[i_bbox][1]), (bboxes[i_bbox][2],bboxes[i_bbox][3]), (0,255,0), 5)  \n",
    "            \n",
    "    if len(prev_bboxes) > 10:\n",
    "        prev_bboxes = []\n",
    "        bbox_disappear_frame_count = 10\n",
    "        \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_img):\n",
    "    \n",
    "    inputs = []\n",
    "    #input_img_cropped = input_img[120:720,680:1280,:]\n",
    "    #img = cv2.resize(input_img_cropped, (300, 300))\n",
    "    img = cv2.resize(input_img, (300, 300))\n",
    "    img = image.img_to_array(img)\n",
    "    inputs.append(img.copy())\n",
    "    inputs = preprocess_input(np.array(inputs))\n",
    "    inputs = np.expand_dims(inputs[0], axis=0)\n",
    "    \n",
    "    preds = model.predict(inputs, batch_size=1, verbose=0)\n",
    "    results = bbox_util.detection_out(preds)\n",
    "    \n",
    "    final_img = draw_boxes(input_img, preds, results)\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_video_SSD_smooth_disappear.mp4\n",
      "[MoviePy] Writing video project_video_video_SSD_smooth_disappear.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [07:17<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_video_SSD_smooth_disappear.mp4 \n",
      "\n",
      "CPU times: user 45min, sys: 3min 22s, total: 48min 23s\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "first_frame_has_car = True\n",
    "prev_bboxes = []\n",
    "bbox_disappear_frame_count = 0\n",
    "prev_bboxes_len = 0\n",
    "\n",
    "output = 'project_video_video_SSD_smooth_disappear.mp4'\n",
    "clip1 = VideoFileClip(\"/tmp/project_video.mp4\")\n",
    "clip = clip1.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-19 23:42:08--  https://images.pexels.com/photos/980382/pexels-photo-980382.jpeg\n",
      "Resolving images.pexels.com (images.pexels.com)... 104.16.238.112, 104.16.239.112, 104.16.240.112, ...\n",
      "Connecting to images.pexels.com (images.pexels.com)|104.16.238.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1836911 (1.8M) [image/jpeg]\n",
      "Saving to: ‘/tmp/test.jpg’\n",
      "\n",
      "/tmp/test.jpg       100%[===================>]   1.75M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-10-19 23:42:08 (39.9 MB/s) - ‘/tmp/test.jpg’ saved [1836911/1836911]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O /tmp/test.jpg https://images.pexels.com/photos/980382/pexels-photo-980382.jpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/tmp/test.jpg'\n",
    "img = image.load_img(file_name, target_size=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "#img = cv2.resize(input_img, (300, 300))\n",
    "img = image.img_to_array(img)\n",
    "inputs.append(img.copy())\n",
    "inputs = preprocess_input(np.array(inputs))\n",
    "inputs = np.expand_dims(inputs[0], axis=0)\n",
    "preds = model.predict(inputs, batch_size=1, verbose=0)\n",
    "#results = bbox_util.detection_out(preds)\n",
    "#final_img = draw_boxes(img, preds, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "payload = json.dumps(inputs.tolist())\n",
    "type(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Simulate what happens on the endpoint__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = json.loads(payload)\n",
    "type(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(parsed)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(data, batch_size=1, verbose=0)\n",
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = json.dumps(predictions.tolist())\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__simulate whats happens on the client__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = np.array(json.loads(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bbox_util.detection_out(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'prev_bboxes_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-20089342adcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-90de1b10dceb>\u001b[0m in \u001b[0;36mdraw_boxes\u001b[0;34m(img, preds, results)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mprev_bboxes_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbboxes_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbbox_disappear_frame_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_prev_bbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_bbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'prev_bboxes_len' is not defined"
     ]
    }
   ],
   "source": [
    "final_image = draw_boxes(img, response, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
