#!/usr/bin/env python

# Libraries
from __future__ import absolute_import
from __future__ import print_function

import cv2
import keras
from keras.applications.imagenet_utils import preprocess_input
from keras.backend.tensorflow_backend import set_session
from keras.models import Model
from keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import pickle
from random import shuffle
from scipy.misc import imread
from scipy.misc import imresize
import tensorflow as tf

from ssd_model import SSD300v2
from ssd_utils import BBoxUtility

from environment import create_trainer_environment

# Set Configuration parameters
np.set_printoptions(suppress=True)
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.95
set_session(tf.Session(config=config))

# Global parameters
voc_classes = ['Aeroplane', 'Bicycle', 'Bird', 'Boat', 'Bottle',
               'Bus', 'Car', 'Cat', 'Chair', 'Cow', 'Diningtable',
               'Dog', 'Horse','Motorbike', 'Person', 'Pottedplant',
               'Sheep', 'Sofa', 'Train', 'Tvmonitor']
NUM_CLASSES = len(voc_classes) + 1
INPUT_SHAPE = (300, 300, 3)
MODEL_NAME = 'model.h5'

# Configure the trainer environemnt for SageMaker training
env = create_trainer_environment()
print('creating SageMaker trainer environment:\n%s' % str(env))

# Get hyperparameters
batch_size = env.hyperparameters.get('batch_size', default=16, object_type=int)
learning_rate = env.hyperparameters.get('learning_rate', default=.001, object_type=float)
EPOCHS = env.hyperparameters.get('epochs', default=10, object_type=int)
gpu_count = env.hyperparameters.get('gpu_count', default=0, object_type=int)

# Helper functions for Image Augmentation
def load_image(data_dir, image_file):
    """
    Load RGB images from a file
    """
    return mpimg.imread(os.path.join(data_dir, image_file.strip()))

def crop(image):
    """
    Crop the image (removing the sky at the top and the car front at the bottom)
    """
    return image[60:-25, :, :] # remove the sky and the car front

def resize(image):
    """
    Resize the image to the input shape used by the network model
    """
    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)

def rgb2yuv(image):
    """
    Convert the image from RGB to YUV (This is what the NVIDIA model does)
    """
    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)

def preprocess(image):
    """
    Combine all preprocess functions into one
    """
    image = crop(image)
    image = resize(image)
    image = rgb2yuv(image)
    return image

def choose_image(data_dir, center, left, right, steering_angle):
    """
    Randomly choose an image from the center, left or right, and adjust
    the steering angle.
    """
    choice = np.random.choice(3)
    if choice == 0:
        return load_image(data_dir, left), steering_angle + 0.2
    elif choice == 1:
        return load_image(data_dir, right), steering_angle - 0.2
    return load_image(data_dir, center), steering_angle

def random_flip(image, steering_angle):
    """
    Randomly flipt the image left <-> right, and adjust the steering angle.
    """
    if np.random.rand() < 0.5:
        image = cv2.flip(image, 1)
        steering_angle = -steering_angle
    return image, steering_angle

def random_translate(image, steering_angle, range_x, range_y):
    """
    Randomly shift the image virtially and horizontally (translation).
    """
    trans_x = range_x * (np.random.rand() - 0.5)
    trans_y = range_y * (np.random.rand() - 0.5)
    steering_angle += trans_x * 0.002
    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])
    height, width = image.shape[:2]
    image = cv2.warpAffine(image, trans_m, (width, height))
    return image, steering_angle

def distort(image):
    """
    Method for adding random distortion to dataset images, including random brightness adjust, and a random
    vertical shift of the horizon position
    """
    new_img = image.astype(float)
    # random brightness - the mask bit keeps values from going beyond (0,255)
    value = np.random.randint(-28, 28)
    if value > 0:
        mask = (new_img[:,:,0] + value) > 255 
    if value <= 0:
        mask = (new_img[:,:,0] + value) < 0
    new_img[:,:,0] += np.where(mask, 0, value)
    # random shadow - full height, random left/right side, random darkening
    h,w = new_img.shape[0:2]
    mid = np.random.randint(0,w)
    factor = np.random.uniform(0.6,0.8)
    if np.random.rand() > .5:
        new_img[:,0:mid,0] *= factor
    else:
        new_img[:,mid:w,0] *= factor
    # randomly shift horizon
    h,w,_ = new_img.shape
    horizon = 2*h/5
    v_shift = np.random.randint(-h/8,h/8)
    pts1 = np.float32([[0,horizon],[w,horizon],[0,h],[w,h]])
    pts2 = np.float32([[0,horizon+v_shift],[w,horizon+v_shift],[0,h],[w,h]])
    M = cv2.getPerspectiveTransform(pts1,pts2)
    new_img = cv2.warpPerspective(new_img,M,(w,h), borderMode=cv2.BORDER_REPLICATE)
    return new_img.astype(np.uint8)

def random_brightness(image):
    """
    Randomly adjust brightness of the image.
    """
    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)
    hsv[:,:,2] =  hsv[:,:,2] * ratio
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

def augment(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):
    """
    Generate an augumented image and adjust steering angle.
    (The steering angle is associated with the center image)
    """
    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)
    image, steering_angle = random_flip(image, steering_angle)
    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)
    image = distort(image)
    image = random_brightness(image)
    return image, steering_angle

def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):
    """
    Generate training image give image paths and associated steering angles
    """
    images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])
    steers = np.empty(batch_size)
    while True:
        i = 0
        for index in np.random.permutation(image_paths.shape[0]):
            center, left, right = image_paths[index]
            steering_angle = steering_angles[index]
            # argumentation
            if is_training and np.random.rand() < 1.:
                image, steering_angle = augment(data_dir, center, left, right, steering_angle)
            else:
                image = load_image(data_dir, center) 
            # add the image and steering angle to the batch
            images[i] = preprocess(image)
            steers[i] = steering_angle
            i += 1
            if i == batch_size:
                break
        yield images, steers

# Helper functions for model training
def load_data(data_dir, test_size):
    """
    Load training data and split it into training and validation set
    """
    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'))

    X = data_df[['center', 'left', 'right']].values
    y = data_df['steering'].values

    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=0)

    return X_train, X_valid, y_train, y_valid

def build_model(input_shape):
    """
    Comma.ai model
    """
    model = Sequential()
    model.add(
        Lambda(
            lambda x: x/127.55 -1,
            input_shape=input_shape
        )
    )
    model.add(Conv2D(16, (8, 8), strides=(4, 4), padding="same"))
    model.add(ELU())
    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding="same"))
    model.add(ELU())
    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding="same"))
    model.add(Flatten())
    model.add(Dropout(.2))
    model.add(ELU())
    model.add(Dense(512))
    model.add(Dropout(.5))
    model.add(ELU())
    model.add(Dense(1))
    model.summary()
    return model

def save(model, model_dir):
    print("Saving the trained model ...")
    files = list(glob.glob(os.path.join(model_dir, '*.h5')))
    
    # Find the best model weights
    best = max(files)
    
    # Rename the best weights
    #os.rename(best, MODEL_NAME)
    shutil.copy(best, os.path.join(model_dir, MODEL_NAME))
    
    # Move to model_dir
    #shutil.copy('./model.h5', model_dir+'/')
    
#    # Save model graph to `.json`
#    model_json = model.to_json()
#    with open(model_dir+'/model.json', 'w') as outfile:
#        json.dump(model_json, outfile)

# Training function
def train():
    print("Starting model training ...")
    # Local variables
    data_dir = os.path.join(env.channel_dirs['train'], 'data')
    test_size = 0.1

    # Load the data
    X_train, X_valid, y_train, y_valid = load_data(data_dir, test_size)
        
    # Load the model and additional parameters
    print("\ncomma.ai Model Summary\n")
    model = build_model(IMAGE_SHAPE)
        
    # Save model Checpoint
    checkpoint = ModelCheckpoint(
        os.path.join(env.model_dir, 'model-{epoch:03d}.h5'),
        verbose=0,
        save_best_only=1,
        mode='auto'
    )

    # Compile model
    if gpu_count > 1:
        model = multi_gpu_model(model, gpus=gpu_count)
    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))
        
    # Fit the model
    model.fit_generator(
        batch_generator(
            data_dir,
            X_train,
            y_train,
            batch_size,
            True
        ),
        steps_per_epoch=len(X_train)//batch_size,
        epochs=EPOCHS,
#        max_queue_size=1,
        validation_data=batch_generator(
            data_dir,
            X_valid,
            y_valid,
            batch_size,
            False
        ),
        validation_steps=len(X_valid)//batch_size,
        callbacks=[checkpoint],
        verbose=1
    )

    # Save the model
    save(model, env.model_dir)

if __name__ == '__main__':
    train()
    sys.exit(0)